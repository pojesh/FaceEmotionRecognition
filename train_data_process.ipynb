{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = r\"c:\\Users\\Pojesh\\Documents\\OfficialWorks\\MV_Project\\Dataset\\affectnet\\YOLO_format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = os.path.join(dataset_root, \"train\")\n",
    "augmented_folder = os.path.join(dataset_root, \"train_augmented\")\n",
    "\n",
    "# Define class names\n",
    "class_names = [\n",
    "    \"Anger\",\n",
    "    \"Contempt\",\n",
    "    \"Disgust\",\n",
    "    \"Fear\",\n",
    "    \"Happy\",\n",
    "    \"Neutral\",\n",
    "    \"Sad\",\n",
    "    \"Surprise\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(augmented_folder, \"images\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(augmented_folder, \"labels\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_classes():\n",
    "    \"\"\"Count the number of images per class in the train folder\"\"\"\n",
    "    class_counts = Counter()\n",
    "    \n",
    "    # Get all label files\n",
    "    label_files = glob.glob(os.path.join(train_folder, \"labels\", \"*.txt\"))\n",
    "    \n",
    "    for label_file in label_files:\n",
    "        try:\n",
    "            with open(label_file, 'r') as f:\n",
    "                first_line = f.readline().strip()\n",
    "                if first_line:\n",
    "                    # The class ID is the first number in the line\n",
    "                    class_id = int(first_line.split()[0])\n",
    "                    class_counts[class_id] += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {label_file}: {e}\")\n",
    "    \n",
    "    return class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_augmentation(image, augmentation_type):\n",
    "    \"\"\"Apply different augmentation techniques to an image\"\"\"\n",
    "    if augmentation_type == 0:\n",
    "        # Horizontal flip\n",
    "        return ImageOps.mirror(image)\n",
    "    elif augmentation_type == 1:\n",
    "        # Brightness adjustment\n",
    "        enhancer = ImageEnhance.Brightness(image)\n",
    "        return enhancer.enhance(random.uniform(0.8, 1.2))\n",
    "    elif augmentation_type == 2:\n",
    "        # Contrast adjustment\n",
    "        enhancer = ImageEnhance.Contrast(image)\n",
    "        return enhancer.enhance(random.uniform(0.8, 1.2))\n",
    "    elif augmentation_type == 3:\n",
    "        # Rotation (slight)\n",
    "        return image.rotate(random.uniform(-15, 15), expand=False)\n",
    "    elif augmentation_type == 4:\n",
    "        # Combination: flip + brightness\n",
    "        img = ImageOps.mirror(image)\n",
    "        enhancer = ImageEnhance.Brightness(img)\n",
    "        return enhancer.enhance(random.uniform(0.8, 1.2))\n",
    "    elif augmentation_type == 5:\n",
    "        # Combination: rotation + contrast\n",
    "        img = image.rotate(random.uniform(-15, 15), expand=False)\n",
    "        enhancer = ImageEnhance.Contrast(img)\n",
    "        return enhancer.enhance(random.uniform(0.8, 1.2))\n",
    "    else:\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset():\n",
    "    \"\"\"Augment the dataset to balance classes\"\"\"\n",
    "    # First, count the current class distribution\n",
    "    class_counts = count_classes()\n",
    "    print(\"Original class distribution:\")\n",
    "    for class_id, count in sorted(class_counts.items()):\n",
    "        print(f\"  {class_names[class_id]}: {count} images\")\n",
    "    \n",
    "    # Find the target count (the highest class count)\n",
    "    target_count = max(class_counts.values())\n",
    "    print(f\"\\nTarget count per class: {target_count}\")\n",
    "    \n",
    "    # Copy all original files to the augmented folder first\n",
    "    print(\"\\nCopying original files...\")\n",
    "    for file_type in [\"images\", \"labels\"]:\n",
    "        original_files = glob.glob(os.path.join(train_folder, file_type, \"*.*\"))\n",
    "        for file_path in original_files:\n",
    "            file_name = os.path.basename(file_path)\n",
    "            shutil.copy2(file_path, os.path.join(augmented_folder, file_type, file_name))\n",
    "    \n",
    "    # Get all label files and their corresponding class IDs\n",
    "    label_files = glob.glob(os.path.join(train_folder, \"labels\", \"*.txt\"))\n",
    "    file_class_map = {}\n",
    "    \n",
    "    for label_path in label_files:\n",
    "        try:\n",
    "            with open(label_path, 'r') as f:\n",
    "                first_line = f.readline().strip()\n",
    "                if first_line:\n",
    "                    class_id = int(first_line.split()[0])\n",
    "                    file_name = os.path.basename(label_path)\n",
    "                    file_class_map[file_name] = class_id\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {label_path}: {e}\")\n",
    "    \n",
    "    # Augment underrepresented classes\n",
    "    print(\"\\nAugmenting underrepresented classes...\")\n",
    "    for class_id in range(len(class_names)):\n",
    "        if class_id not in class_counts or class_counts[class_id] >= target_count:\n",
    "            continue\n",
    "        \n",
    "        # Calculate how many more images we need\n",
    "        needed = target_count - class_counts[class_id]\n",
    "        print(f\"  {class_names[class_id]}: need to generate {needed} more images\")\n",
    "        \n",
    "        # Get all files of this class\n",
    "        class_files = [file_name for file_name, file_class in file_class_map.items() if file_class == class_id]\n",
    "        \n",
    "        # Generate augmented images\n",
    "        augmented_count = 0\n",
    "        while augmented_count < needed:\n",
    "            # Select a random file to augment\n",
    "            label_file = random.choice(class_files)\n",
    "            image_file = os.path.splitext(label_file)[0] + \".jpg\"  # Try jpg first\n",
    "            \n",
    "            # Check if jpg exists, if not try other extensions\n",
    "            image_path = os.path.join(train_folder, \"images\", image_file)\n",
    "            if not os.path.exists(image_path):\n",
    "                image_file = os.path.splitext(label_file)[0] + \".jpeg\"\n",
    "                image_path = os.path.join(train_folder, \"images\", image_file)\n",
    "            if not os.path.exists(image_path):\n",
    "                image_file = os.path.splitext(label_file)[0] + \".png\"\n",
    "                image_path = os.path.join(train_folder, \"images\", image_file)\n",
    "            \n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"    Warning: Could not find image for {label_file}\")\n",
    "                continue\n",
    "            \n",
    "            # Load the image\n",
    "            try:\n",
    "                image = Image.open(image_path)\n",
    "                \n",
    "                # Apply a random augmentation\n",
    "                aug_type = random.randint(0, 5)  # 6 different augmentation types\n",
    "                augmented_image = apply_augmentation(image, aug_type)\n",
    "                \n",
    "                # Save the augmented image and label\n",
    "                aug_suffix = f\"_aug_{augmented_count}\"\n",
    "                new_image_name = os.path.splitext(image_file)[0] + aug_suffix + os.path.splitext(image_file)[1]\n",
    "                new_label_name = os.path.splitext(label_file)[0] + aug_suffix + \".txt\"\n",
    "                \n",
    "                augmented_image.save(os.path.join(augmented_folder, \"images\", new_image_name))\n",
    "                shutil.copy2(\n",
    "                    os.path.join(train_folder, \"labels\", label_file),\n",
    "                    os.path.join(augmented_folder, \"labels\", new_label_name)\n",
    "                )\n",
    "                \n",
    "                augmented_count += 1\n",
    "                if augmented_count % 100 == 0:\n",
    "                    print(f\"    Generated {augmented_count}/{needed} augmented images for {class_names[class_id]}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"    Error processing {image_path}: {e}\")\n",
    "    \n",
    "    # Count the new class distribution\n",
    "    print(\"\\nVerifying augmented dataset...\")\n",
    "    augmented_class_counts = Counter()\n",
    "    augmented_label_files = glob.glob(os.path.join(augmented_folder, \"labels\", \"*.txt\"))\n",
    "    \n",
    "    for label_file in augmented_label_files:\n",
    "        try:\n",
    "            with open(label_file, 'r') as f:\n",
    "                first_line = f.readline().strip()\n",
    "                if first_line:\n",
    "                    class_id = int(first_line.split()[0])\n",
    "                    augmented_class_counts[class_id] += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {label_file}: {e}\")\n",
    "    \n",
    "    print(\"\\nFinal class distribution:\")\n",
    "    for class_id in range(len(class_names)):\n",
    "        print(f\"  {class_names[class_id]}: {augmented_class_counts.get(class_id, 0)} images\")\n",
    "    \n",
    "    # Plot the class distribution before and after augmentation\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(range(len(class_names)), [class_counts.get(i, 0) for i in range(len(class_names))])\n",
    "    plt.xticks(range(len(class_names)), class_names, rotation=45)\n",
    "    plt.title(\"Original Class Distribution\")\n",
    "    plt.ylabel(\"Number of Images\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(range(len(class_names)), [augmented_class_counts.get(i, 0) for i in range(len(class_names))])\n",
    "    plt.xticks(range(len(class_names)), class_names, rotation=45)\n",
    "    plt.title(\"Augmented Class Distribution\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(dataset_root, \"class_distribution.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\nAugmentation complete! Augmented dataset saved to {augmented_folder}\")\n",
    "    print(f\"Class distribution visualization saved to {os.path.join(dataset_root, 'class_distribution.png')}\")\n",
    "    \n",
    "    # Update data.yaml to include the augmented dataset\n",
    "    update_data_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data_yaml():\n",
    "    \"\"\"Update the data.yaml file to use the augmented dataset\"\"\"\n",
    "    yaml_path = os.path.join(dataset_root, \"data.yaml\")\n",
    "    \n",
    "    if os.path.exists(yaml_path):\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Update the train path\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.strip().startswith(\"train:\"):\n",
    "                # Get the base path\n",
    "                base_path = line.split(\":\")[1].strip().rsplit(\"/\", 3)[0]\n",
    "                lines[i] = f'train: \"{base_path}/train_augmented/images\"\\n'\n",
    "        \n",
    "        # Write the updated yaml file\n",
    "        with open(yaml_path, 'w') as f:\n",
    "            f.writelines(lines)\n",
    "        \n",
    "        print(f\"\\nUpdated {yaml_path} to use the augmented dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "  Anger: 2339 images\n",
      "  Contempt: 1996 images\n",
      "  Disgust: 2242 images\n",
      "  Fear: 2021 images\n",
      "  Happy: 2154 images\n",
      "  Neutral: 1616 images\n",
      "  Sad: 1914 images\n",
      "  Surprise: 2819 images\n",
      "\n",
      "Target count per class: 2819\n",
      "\n",
      "Copying original files...\n",
      "\n",
      "Augmenting underrepresented classes...\n",
      "  Anger: need to generate 480 more images\n",
      "    Generated 100/480 augmented images for Anger\n",
      "    Generated 200/480 augmented images for Anger\n",
      "    Generated 300/480 augmented images for Anger\n",
      "    Generated 400/480 augmented images for Anger\n",
      "  Contempt: need to generate 823 more images\n",
      "    Generated 100/823 augmented images for Contempt\n",
      "    Generated 200/823 augmented images for Contempt\n",
      "    Generated 300/823 augmented images for Contempt\n",
      "    Generated 400/823 augmented images for Contempt\n",
      "    Generated 500/823 augmented images for Contempt\n",
      "    Generated 600/823 augmented images for Contempt\n",
      "    Generated 700/823 augmented images for Contempt\n",
      "    Generated 800/823 augmented images for Contempt\n",
      "  Disgust: need to generate 577 more images\n",
      "    Generated 100/577 augmented images for Disgust\n",
      "    Generated 200/577 augmented images for Disgust\n",
      "    Generated 300/577 augmented images for Disgust\n",
      "    Generated 400/577 augmented images for Disgust\n",
      "    Generated 500/577 augmented images for Disgust\n",
      "  Fear: need to generate 798 more images\n",
      "    Generated 100/798 augmented images for Fear\n",
      "    Generated 200/798 augmented images for Fear\n",
      "    Generated 300/798 augmented images for Fear\n",
      "    Generated 400/798 augmented images for Fear\n",
      "    Generated 500/798 augmented images for Fear\n",
      "    Generated 600/798 augmented images for Fear\n",
      "    Generated 700/798 augmented images for Fear\n",
      "  Happy: need to generate 665 more images\n",
      "    Generated 100/665 augmented images for Happy\n",
      "    Generated 200/665 augmented images for Happy\n",
      "    Generated 300/665 augmented images for Happy\n",
      "    Generated 400/665 augmented images for Happy\n",
      "    Generated 500/665 augmented images for Happy\n",
      "    Generated 600/665 augmented images for Happy\n",
      "  Neutral: need to generate 1203 more images\n",
      "    Generated 100/1203 augmented images for Neutral\n",
      "    Generated 200/1203 augmented images for Neutral\n",
      "    Generated 300/1203 augmented images for Neutral\n",
      "    Generated 400/1203 augmented images for Neutral\n",
      "    Generated 500/1203 augmented images for Neutral\n",
      "    Generated 600/1203 augmented images for Neutral\n",
      "    Generated 700/1203 augmented images for Neutral\n",
      "    Generated 800/1203 augmented images for Neutral\n",
      "    Generated 900/1203 augmented images for Neutral\n",
      "    Generated 1000/1203 augmented images for Neutral\n",
      "    Generated 1100/1203 augmented images for Neutral\n",
      "    Generated 1200/1203 augmented images for Neutral\n",
      "  Sad: need to generate 905 more images\n",
      "    Generated 100/905 augmented images for Sad\n",
      "    Generated 200/905 augmented images for Sad\n",
      "    Generated 300/905 augmented images for Sad\n",
      "    Generated 400/905 augmented images for Sad\n",
      "    Generated 500/905 augmented images for Sad\n",
      "    Generated 600/905 augmented images for Sad\n",
      "    Generated 700/905 augmented images for Sad\n",
      "    Generated 800/905 augmented images for Sad\n",
      "    Generated 900/905 augmented images for Sad\n",
      "\n",
      "Verifying augmented dataset...\n",
      "\n",
      "Final class distribution:\n",
      "  Anger: 2819 images\n",
      "  Contempt: 2819 images\n",
      "  Disgust: 2819 images\n",
      "  Fear: 2819 images\n",
      "  Happy: 2819 images\n",
      "  Neutral: 2819 images\n",
      "  Sad: 2819 images\n",
      "  Surprise: 2819 images\n",
      "\n",
      "Augmentation complete! Augmented dataset saved to c:\\Users\\Pojesh\\Documents\\OfficialWorks\\MV_Project\\Dataset\\affectnet\\YOLO_format\\train_augmented\n",
      "Class distribution visualization saved to c:\\Users\\Pojesh\\Documents\\OfficialWorks\\MV_Project\\Dataset\\affectnet\\YOLO_format\\class_distribution.png\n",
      "\n",
      "Updated c:\\Users\\Pojesh\\Documents\\OfficialWorks\\MV_Project\\Dataset\\affectnet\\YOLO_format\\data.yaml to use the augmented dataset\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    augment_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mv_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
