{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eee2041",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4914cf7e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- Step 1: Localization Network ---\n",
    "class LocalizationNetwork(tf.keras.Model): # [cite: 2]\n",
    "    def __init__(self):\n",
    "        super(LocalizationNetwork, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') # [cite: 2]\n",
    "        self.pool1 = layers.MaxPooling2D((2, 2)) # [cite: 2]\n",
    "        self.conv2 = layers.Conv2D(10, (3, 3), activation='relu', padding='same') # [cite: 2]\n",
    "        self.pool2 = layers.MaxPooling2D((2, 2)) # [cite: 2]\n",
    "        self.flatten = layers.Flatten() # [cite: 2]\n",
    "        self.fc1 = layers.Dense(32, activation='relu') # [cite: 3]\n",
    "        self.fc2 = layers.Dense( # [cite: 3]\n",
    "            6,\n",
    "            activation=None,\n",
    "            kernel_initializer='zeros',\n",
    "            bias_initializer=tf.keras.initializers.Constant([1, 0, 0, 0, 1, 0])  # Identity transform\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.pool1(self.conv1(x)) # [cite: 3]\n",
    "        x = self.pool2(self.conv2(x)) # [cite: 4]\n",
    "        x = self.flatten(x) # [cite: 4]\n",
    "        x = self.fc1(x) # [cite: 4]\n",
    "        theta = self.fc2(x) # [cite: 4]\n",
    "        return theta # [cite: 4]\n",
    "\n",
    "\n",
    "# --- Step 2: Grid Generator and Bilinear Sampler ---\n",
    "def affine_grid_generator(theta, input_size): #\n",
    "    \"\"\"Generates a sampling grid for the affine transform.\"\"\"\n",
    "    # Explicitly cast shape components to int32\n",
    "    num_batch = tf.cast(input_size[0], tf.int32)\n",
    "    H = tf.cast(input_size[1], tf.int32)\n",
    "    W = tf.cast(input_size[2], tf.int32)\n",
    "\n",
    "    theta = tf.reshape(theta, [-1, 2, 3]) # (N, 2, 3)\n",
    "\n",
    "    # Normalized grid coordinates\n",
    "    x = tf.linspace(-1.0, 1.0, W) # W should be int32\n",
    "    y = tf.linspace(-1.0, 1.0, H) # H should be int32\n",
    "    x_t, y_t = tf.meshgrid(x, y) # Shapes (H, W), (H, W)\n",
    "\n",
    "    ones = tf.ones_like(x_t) # (H, W)\n",
    "    sampling_grid = tf.stack([x_t, y_t, ones], axis=2) # (H, W, 3)\n",
    "\n",
    "    # Flatten grid\n",
    "    sampling_grid = tf.reshape(sampling_grid, [1, -1, 3])  # (1, H*W, 3)\n",
    "\n",
    "    # Repeat grid num_batch times\n",
    "    sampling_grid = tf.tile(sampling_grid, [num_batch, 1, 1])  # (N, H*W, 3)\n",
    "\n",
    "    # Transform grid\n",
    "    # theta shape: (N, 2, 3)\n",
    "    # sampling_grid shape: (N, H*W, 3)\n",
    "    # Need to transpose sampling_grid for matmul: (N, 3, H*W)\n",
    "    grid = tf.matmul(theta, sampling_grid, transpose_b=True)  # (N, 2, H*W)\n",
    "\n",
    "    # Transpose to (N, H*W, 2) for sampler compatibility\n",
    "    grid = tf.transpose(grid, [0, 2, 1])\n",
    "\n",
    "    # Reshape grid back to (N, H, W, 2)\n",
    "    # Ensure all components of the target shape are int32\n",
    "    target_shape = tf.stack([num_batch, H, W, 2])\n",
    "    grid = tf.reshape(grid, target_shape)\n",
    "\n",
    "    return grid #\n",
    "\n",
    "\n",
    "def bilinear_sampler(img, grid): # [cite: 6] Modified to remove unused output_size\n",
    "    \"\"\"Performs bilinear sampling of the input images according to the normalized grid.\"\"\"\n",
    "    B = tf.shape(img)[0] # [cite: 6]\n",
    "    H = tf.cast(tf.shape(img)[1], tf.float32) # [cite: 6]\n",
    "    W = tf.cast(tf.shape(img)[2], tf.float32) # [cite: 6]\n",
    "    C = tf.shape(img)[3] # [cite: 6]\n",
    "\n",
    "    x_s = grid[..., 0] # [cite: 6]\n",
    "    y_s = grid[..., 1] # [cite: 6]\n",
    "\n",
    "    # Scale normalized coordinates to image size\n",
    "    x = ((x_s + 1.0) * 0.5) * (W - 1.0) # [cite: 6]\n",
    "    y = ((y_s + 1.0) * 0.5) * (H - 1.0) # [cite: 6]\n",
    "\n",
    "    x0 = tf.cast(tf.floor(x), tf.int32) # [cite: 7]\n",
    "    x1 = x0 + 1 # [cite: 7]\n",
    "    y0 = tf.cast(tf.floor(y), tf.int32) # [cite: 7]\n",
    "    y1 = y0 + 1 # [cite: 7]\n",
    "\n",
    "    x0 = tf.clip_by_value(x0, 0, tf.cast(W - 1, tf.int32)) # [cite: 7]\n",
    "    x1 = tf.clip_by_value(x1, 0, tf.cast(W - 1, tf.int32)) # [cite: 7]\n",
    "    y0 = tf.clip_by_value(y0, 0, tf.cast(H - 1, tf.int32)) # [cite: 7]\n",
    "    y1 = tf.clip_by_value(y1, 0, tf.cast(H - 1, tf.int32)) # [cite: 7]\n",
    "\n",
    "    # Gather pixel values using tf.gather_nd\n",
    "    batch_indices = tf.tile(tf.reshape(tf.range(B), [B, 1, 1]), [1, tf.cast(H, tf.int32), tf.cast(W, tf.int32)]) # [cite: 8] Explicitly cast H, W\n",
    "\n",
    "    def gather_pixels(y_indices, x_indices):\n",
    "        indices = tf.stack([batch_indices, y_indices, x_indices], axis=-1) # [cite: 8]\n",
    "        return tf.gather_nd(img, indices) # [cite: 8]\n",
    "\n",
    "    I00 = gather_pixels(y0, x0) # [cite: 8]\n",
    "    I01 = gather_pixels(y1, x0) # [cite: 8]\n",
    "    I10 = gather_pixels(y0, x1) # [cite: 8]\n",
    "    I11 = gather_pixels(y1, x1) # [cite: 8]\n",
    "\n",
    "    # Interpolation weights\n",
    "    x = tf.cast(x, tf.float32) # [cite: 8]\n",
    "    y = tf.cast(y, tf.float32) # [cite: 8]\n",
    "    x0_f = tf.cast(x0, tf.float32) # [cite: 9]\n",
    "    y0_f = tf.cast(y0, tf.float32) # [cite: 9]\n",
    "    x1_f = tf.cast(x1, tf.float32) # Calculate x1_f needed for weights\n",
    "    y1_f = tf.cast(y1, tf.float32) # Calculate y1_f needed for weights\n",
    "\n",
    "    wa = (x1_f - x) * (y1_f - y) # [cite: 9]\n",
    "    wb = (x1_f - x) * (y - y0_f) # [cite: 9]\n",
    "    wc = (x - x0_f) * (y1_f - y) # [cite: 9]\n",
    "    wd = (x - x0_f) * (y - y0_f) # [cite: 9]\n",
    "\n",
    "    wa = tf.expand_dims(wa, -1) # [cite: 9]\n",
    "    wb = tf.expand_dims(wb, -1) # [cite: 9]\n",
    "    wc = tf.expand_dims(wc, -1) # [cite: 9]\n",
    "    wd = tf.expand_dims(wd, -1) # [cite: 9]\n",
    "\n",
    "    out = wa * I00 + wb * I01 + wc * I10 + wd * I11 # [cite: 9, 10]\n",
    "    return out # [cite: 10]\n",
    "\n",
    "\n",
    "# --- Step 3: STN Layer ---\n",
    "class STN(tf.keras.layers.Layer): # [cite: 10]\n",
    "    def __init__(self):\n",
    "        super(STN, self).__init__()\n",
    "        self.localization_net = LocalizationNetwork() # [cite: 10]\n",
    "\n",
    "    def call(self, x):\n",
    "        theta = self.localization_net(x) # [cite: 10]\n",
    "        input_shape = tf.shape(x) # [cite: 10] # Pass dynamic shape\n",
    "        grid = affine_grid_generator(theta, input_shape) # [cite: 10]\n",
    "        sampled = bilinear_sampler(x, grid) # [cite: 11] Removed output_size argument\n",
    "        return sampled # [cite: 11]\n",
    "\n",
    "\n",
    "# --- Step 4: Full Emotion Recognition Model ---\n",
    "def build_model(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES): # [cite: 11]\n",
    "    inputs = Input(shape=input_shape) # [cite: 11]\n",
    "    x = STN()(inputs) # [cite: 11]\n",
    "\n",
    "    # Feature extraction\n",
    "    x = layers.Conv2D(10, (3, 3), activation='relu', padding='same')(x) # [cite: 11]\n",
    "    x = layers.Conv2D(10, (3, 3), activation='relu', padding='same')(x) # [cite: 11]\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x) # [cite: 11]\n",
    "\n",
    "    x = layers.Conv2D(10, (3, 3), activation='relu', padding='same')(x) # [cite: 11]\n",
    "    x = layers.Conv2D(10, (3, 3), activation='relu', padding='same')(x) # [cite: 11]\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x) # [cite: 12]\n",
    "\n",
    "    x = layers.Flatten()(x) # [cite: 12]\n",
    "    x = layers.Dropout(0.5)(x) # [cite: 12]\n",
    "    x = layers.Dense(50, activation='relu')(x) # [cite: 12]\n",
    "    output = layers.Dense(num_classes, activation='softmax')(x) # [cite: 12]\n",
    "\n",
    "    return models.Model(inputs, output) # [cite: 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d57ac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Model: \"model_3\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " input_4 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
    "                                                                 \n",
    " stn_3 (STN)                 (None, 96, 96, 3)         185504    \n",
    "                                                                 \n",
    " conv2d_20 (Conv2D)          (None, 96, 96, 10)        280       \n",
    "                                                                 \n",
    " conv2d_21 (Conv2D)          (None, 96, 96, 10)        910       \n",
    "                                                                 \n",
    " max_pooling2d_14 (MaxPoolin  (None, 48, 48, 10)       0         \n",
    " g2D)                                                            \n",
    "                                                                 \n",
    " conv2d_22 (Conv2D)          (None, 48, 48, 10)        910       \n",
    "                                                                 \n",
    " conv2d_23 (Conv2D)          (None, 48, 48, 10)        910       \n",
    "                                                                 \n",
    " max_pooling2d_15 (MaxPoolin  (None, 24, 24, 10)       0         \n",
    " g2D)                                                            \n",
    "                                                                 \n",
    " flatten_7 (Flatten)         (None, 5760)              0         \n",
    "                                                                 \n",
    " dropout_3 (Dropout)         (None, 5760)              0         \n",
    "                                                                 \n",
    " dense_14 (Dense)            (None, 50)                288050    \n",
    "                                                                 \n",
    " dense_15 (Dense)            (None, 8)                 408       \n",
    "                                                                 \n",
    "=================================================================\n",
    "Total params: 476,972\n",
    "Trainable params: 476,972\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
